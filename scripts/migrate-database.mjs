#!/usr/bin/env node

import { createClient } from '@supabase/supabase-js';
import { readFileSync } from 'fs';
import { fileURLToPath } from 'url';
import { dirname, join } from 'path';
import 'dotenv/config';

const __dirname = dirname(fileURLToPath(import.meta.url));

async function migrateDatabase() {
  console.log('ğŸ—„ï¸  Starting Restaurant Daily Database Migration...\n');

  // Get Supabase configuration
  const supabaseUrl = process.env.SUPABASE_URL;
  const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY;

  if (!supabaseUrl || !supabaseKey) {
    console.error('âŒ Missing Supabase configuration');
    console.log('Required: SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY');
    console.log('Check .env.local or Vault configuration');
    process.exit(1);
  }

  console.log(`ğŸ“ Database URL: ${supabaseUrl}`);
  console.log(`ğŸ”‘ Service Key: ${supabaseKey.substring(0, 20)}...`);

  // Create Supabase client
  const supabase = createClient(supabaseUrl, supabaseKey, {
    auth: { autoRefreshToken: false, persistSession: false }
  });

  try {
    // Test connection first
    console.log('\nğŸ” Testing database connection...');
    const { data, error } = await supabase
      .from('_test_')
      .select('*')
      .limit(1);

    if (error && error.code !== 'PGRST106') {
      throw new Error(`Connection failed: ${error.message}`);
    }
    console.log('âœ… Database connection successful');

    // Read migration SQL
    const sqlPath = join(__dirname, 'setup-database.sql');
    console.log(`\nğŸ“„ Reading migration file: ${sqlPath}`);

    const migrationSQL = readFileSync(sqlPath, 'utf8');
    console.log(`âœ… Migration SQL loaded (${migrationSQL.length} characters)`);

    // For now, we'll use the postgresql connection directly
    console.log('\nğŸ“‹ Migration script prepared');
    console.log('ğŸ”§ Creating database setup command...');

    // Get database URL from Vault or environment
    let databaseUrl;
    try {
      // Try to get from Vault first
      const { exec } = await import('child_process');
      const { promisify } = await import('util');
      const execAsync = promisify(exec);

      const vaultToken = process.env.VAULT_TOKEN;
      if (vaultToken) {
        try {
          const { stdout } = await execAsync('vault kv get -format=json secret/supabase', {
            env: { ...process.env, VAULT_ADDR: 'http://127.0.0.1:8200' }
          });
          const vaultData = JSON.parse(stdout);
          databaseUrl = vaultData.data?.data?.database_url;
          if (databaseUrl) {
            console.log('âœ… Database URL retrieved from Vault');
          }
        } catch {
          console.log('âš ï¸  Vault unavailable, using environment fallback');
        }
      }
    } catch {
      console.log('âš ï¸  Using environment fallback for database URL');
    }

    // Fallback to constructing URL from Supabase credentials
    if (!databaseUrl) {
      console.log('ğŸ”§ Constructing database URL from Supabase credentials...');

      // Parse project info from Supabase URL
      const urlMatch = supabaseUrl.match(/https:\/\/([^.]+)\.supabase\.co/);
      if (urlMatch) {
        const projectRef = urlMatch[1];
        databaseUrl = `postgresql://postgres:[POOLER_PASSWORD]@db.${projectRef}.supabase.co:5432/postgres`;
        console.log('ğŸ“‹ Database URL template created');
        console.log('âš ï¸  You may need to set the POOLER_PASSWORD manually');
      }
    }

    console.log('\nğŸš€ Migration preparation completed!');
    console.log('');
    console.log('ğŸ“‹ To complete the migration, you have two options:');
    console.log('');
    console.log('Option 1: Using psql (if available):');
    console.log(`psql "${databaseUrl}" < scripts/setup-database.sql`);
    console.log('');
    console.log('Option 2: Copy and paste in Supabase Dashboard:');
    console.log('1. Go to Supabase Dashboard â†’ SQL Editor');
    console.log('2. Copy contents of scripts/setup-database.sql');
    console.log('3. Paste and run in SQL Editor');
    console.log('');

    // Verify tables were created
    console.log('\nğŸ” Verifying table creation...');
    const { data: tables, error: tableError } = await supabase
      .from('information_schema.tables')
      .select('table_name')
      .eq('table_schema', 'public')
      .in('table_name', ['restaurants', 'users', 'staff_invitations']);

    if (tableError) {
      throw tableError;
    }

    const tableNames = tables?.map(t => t.table_name) || [];
    console.log(`ğŸ“‹ Found tables: ${tableNames.join(', ')}`);

    if (tableNames.length >= 3) {
      console.log('\nğŸ‰ Database migration completed successfully!');
      console.log('âœ… All core tables are ready');
      console.log('ğŸš€ Application can now use real database operations');
    } else {
      console.log('\nâš ï¸  Migration partially completed');
      console.log('Some tables may be missing - check Supabase dashboard');
    }

  } catch (error) {
    console.error('\nâŒ Migration failed:', error.message);
    console.error('ğŸ” Check Supabase credentials and connection');
    process.exit(1);
  }
}

// Handle direct execution
if (import.meta.url === `file://${process.argv[1]}`) {
  migrateDatabase().catch(error => {
    console.error('Migration error:', error);
    process.exit(1);
  });
}